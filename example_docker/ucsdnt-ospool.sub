universe = container

container_image = osdf:///ospool/ap40/data/kapui.mok/ucsdntospooltest.sif
# Specify your executable (single binary or a script that runs several
#  commands) and arguments to be passed to jobs. 
#  $(Process) will be a integer number for each job, starting with "0"
#  and increasing for the relevant number of jobs.


#executable = /code/ucsdnt-trace.py
arguments =  -i /caida/protected/ucsd-nt.sample.pcap.enc -o /output/output.csv -t caida_cskpmok.txt -p osdf_enc_pass.txt

# Specify the name of the log, standard error, and standard output (or "screen output") files. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.

log = ucsdnt-ospool_$(Cluster)_$(Process).log
error = ucsdnt-ospool_$(Cluster)_$(Process).err
output = ucsdnt-ospool_$(Cluster)_$(Process).out

# This lines *would* be used if there were any other files
# needed for the executable to use.
transfer_input_files = caida_cskpmok.txt,osdf_enc_pass.txt

# Specify Job duration category as "Medium" (expected runtime <10 hr) or "Long" (expected runtime <20 hr). 
+JobDurationCategory = "Medium"

# Tell HTCondor requirements (e.g., operating system) your job needs, 
# what amount of compute resources each job will need on the computer where it runs.
#requirements = (OSGVO_OS_STRING == "RHEL 9")
request_cpus = 1
request_memory = 1GB
request_disk = 5GB

# Tell HTCondor to run 3 instances of our job:
queue 1
